app:
  name: "KnowledgeHub AI"
  top_k: 3

paths:
  dataset_dir: "./data"
  vector_store_dir: "./vector_store"
  context_file: "./data/context_summary.txt" # Stores the "Brain" summary

embedding:
  provider: "ollama"
  model: "nomic-embed-text" 

llm:
  active_provider: "ollama" # Options: ollama, openai, gemini, anthropic
  
  default_params:
    temperature: 0.1
    max_tokens: 512

  providers:
    ollama:
      model: "llama3.2:1b"       
      base_url: "http://localhost:11434"
    
    openai:
      api_key: "YOUR_OPENAI_API_KEY" # Replace with your key
      model: "gpt-4o-mini"
      
    gemini:
      api_key: "YOUR_GEMINI_API_KEY" # Replace with your key
      model: "gemini-1.5-flash"
      
    anthropic:
      api_key: "YOUR_ANTHROPIC_API_KEY" # Replace with your key
      model: "claude-3-haiku-20240307"

brain:
  use_web_search: true
  router_model: "ollama" # Model used for quick routing decisions (keep it small/fast)
  summary_model: "ollama" # Model used to generate initial context summary

vector_db:
  type: "chroma"
  collecton_name: "company_knowledge"
  persist_directory: "./vector_store"

chunking:
  chunk_size: 500
  chunk_overlap: 50

server:
  host: "localhost"
  port: 5000
